{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size 6252\n",
      "Train size 5626\n",
      "Test size 626\n",
      "Data saved to different directories successfully.\n",
      "5626\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import utils as vutils\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from PIL import Image\n",
    "\n",
    "class  ImageFolder(Dataset):\n",
    "    \"\"\"docstring for ArtDataset\"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        super( ImageFolder, self).__init__()\n",
    "        self.root = root\n",
    "\n",
    "        self.frame = self._parse_frame()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _parse_frame(self):\n",
    "        frame = []\n",
    "        img_names = os.listdir(self.root)\n",
    "        img_names.sort()\n",
    "        for i in range(len(img_names)):\n",
    "            image_path = os.path.join(self.root, img_names[i])\n",
    "            if image_path[-4:] == '.jpg' or image_path[-4:] == '.png' or image_path[-5:] == '.jpeg': \n",
    "                frame.append(image_path)\n",
    "        return frame\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.frame[idx]\n",
    "        img = Image.open(file).convert('RGB')\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img) \n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_list = [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "trans = transforms.Compose(transform_list)\n",
    "\n",
    "data_root = os.path.join(os.getcwd(), \"datasets\", \"BV\", \"img\")\n",
    "dataset = ImageFolder(root=data_root, transform=trans)\n",
    "\n",
    "# Step 2: Shuffle the dataset randomly\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "if shuffle_dataset:\n",
    "    torch.manual_seed(random_seed)\n",
    "    indices = torch.randperm(len(dataset))\n",
    "\n",
    "# Step 3: Split the shuffled dataset into train and test subsets\n",
    "# Replace 'train_ratio' with the desired ratio for the training set (e.g., 0.8 for 80% training data)\n",
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "print ('Dataset size %d' % len(dataset))\n",
    "print ('Train size %d' % train_size)\n",
    "print ('Test size %d' % test_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Step 4: Create DataLoader objects for train and test subsets\n",
    "# Set 'batch_size' to the desired batch size you want for training and testing\n",
    "train_dir = os.path.join(os.getcwd(), \"datasets\", \"BV\", \"train\")\n",
    "test_dir = os.path.join(os.getcwd(), \"datasets\", \"BV\", \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(train_dataset):\n",
    "    # Save the image with a unique filename in the class directory\n",
    "    vutils.save_image(img, train_dir + '/%d.jpg' % i)\n",
    "\n",
    "for i, img in enumerate(test_dataset):\n",
    "    vutils.save_image(img, test_dir + '/%d.jpg' % i)\n",
    "\n",
    "    \n",
    "print(\"Data saved to different directories successfully.\")\n",
    "print (len([name for name in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, name))]))\n",
    "print (len([name for name in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, name))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5626, 3, 256, 256)\n",
      "(626, 3, 256, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1106116608 into shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mprint\u001b[39m(train_data\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(test_data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 39\u001b[0m train_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(train_data, train_data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     40\u001b[0m test_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(test_data, test_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(train_data\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Ale\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    202\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\Ale\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1106116608 into shape (3,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Step 1: Define the folders for train and test images\n",
    "train_dir = os.path.join(os.getcwd(), 'datasets', 'BV', 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'datasets', 'BV', 'test')\n",
    "\n",
    "# Step 2: Process the images (e.g., resizing, transformations, etc.)\n",
    "# Replace these transformations with the desired ones for your use case\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Load and process train images\n",
    "train_data = []\n",
    "for filename in os.listdir(train_dir):\n",
    "    input_path = os.path.join(train_dir, filename)\n",
    "    img = Image.open(input_path)\n",
    "    img = data_transform(img)\n",
    "    train_data.append(img.numpy())\n",
    "\n",
    "# Load and process test images\n",
    "test_data = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    input_path = os.path.join(test_dir, filename)\n",
    "    img = Image.open(input_path)\n",
    "    img = data_transform(img)\n",
    "    test_data.append(img.numpy())\n",
    "\n",
    "# Step 3: Combine the NumPy arrays into a single NumPy matrix\n",
    "train_data = np.stack(train_data)\n",
    "test_data = np.stack(test_data)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data = np.reshape(train_data, train_data.shape[1]*256*256)\n",
    "test_data = np.reshape(test_data, test_data.shape[1]*256*256)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# Save the train and test data as .npy files (optional)\n",
    "np.save('train_data.npy', train_data)\n",
    "np.save('test_data.npy', test_data)\n",
    "\n",
    "print(\"Train and test data converted to NumPy matrices successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
