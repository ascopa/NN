{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from scipy import linalg\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "class FIDScore:\n",
    "    def __init__(self, path_a, path_b, image_size, batch_size, device='cuda'):\n",
    "        self.device = device\n",
    "        self.image_size = image_size\n",
    "        self.path_a = path_a\n",
    "        self.path_b = path_b\n",
    "        self.batch_size = batch_size\n",
    "        self.inception = self.load_patched_inception_v3().eval().to(device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, loader):\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            print(f\"Batch {batch_idx} - Data shape: {data.shape}, Target shape: {target.shape}\")\n",
    "        pbar = tqdm(loader)\n",
    "        feature_list = []\n",
    "        for img, _ in loader:\n",
    "            img = img.to(self.device)\n",
    "            feature = self.inception(img)[0].view(img.shape[0], -1)\n",
    "            feature_list.append(feature.to('cpu'))\n",
    "        features = torch.cat(feature_list, 0)\n",
    "        return features\n",
    "\n",
    "    def calc_fid(self, sample_mean, sample_cov, real_mean, real_cov, eps=1e-6):\n",
    "        cov_sqrt, _ = linalg.sqrtm(sample_cov @ real_cov, disp=False)\n",
    "        if not np.isfinite(cov_sqrt).all():\n",
    "            print('product of cov matrices is singular')\n",
    "            offset = np.eye(sample_cov.shape[0]) * eps\n",
    "            cov_sqrt = linalg.sqrtm((sample_cov + offset) @ (real_cov + offset))\n",
    "        if np.iscomplexobj(cov_sqrt):\n",
    "            if not np.allclose(np.diagonal(cov_sqrt).imag, 0, atol=1e-3):\n",
    "                m = np.max(np.abs(cov_sqrt.imag))\n",
    "                raise ValueError(f'Imaginary component {m}')\n",
    "            cov_sqrt = cov_sqrt.real\n",
    "        mean_diff = sample_mean - real_mean\n",
    "        mean_norm = mean_diff @ mean_diff\n",
    "        trace = np.trace(sample_cov) + np.trace(real_cov) - 2 * np.trace(cov_sqrt)\n",
    "        fid = mean_norm + trace\n",
    "        return fid\n",
    "\n",
    "    def __call__(self, num_workers=4):\n",
    "        dset_a = ImageFolder(self.path_a, self.transform)\n",
    "       \n",
    "        print(\"Number of real images:\", len(dset_a))\n",
    "        loader_a = DataLoader(dset_a, batch_size=self.batch_size, num_workers=num_workers)\n",
    "        features_a = self.extract_features(loader_a).numpy()\n",
    "        real_mean = np.mean(features_a, 0)\n",
    "        real_cov = np.cov(features_a, rowvar=False)\n",
    "\n",
    "        dset_b = ImageFolder(self.path_b, self.transform)\n",
    "        print(\"Number of synthetic images:\", len(dset_b))\n",
    "        loader_b = DataLoader(dset_b, batch_size=self.batch_size, num_workers=num_workers, drop_last=True)\n",
    "        features_b = self.extract_features(loader_b).numpy()\n",
    "        sample_mean = np.mean(features_b, 0)\n",
    "        sample_cov = np.cov(features_b, rowvar=False)\n",
    "\n",
    "        fid = self.calc_fid(sample_mean, sample_cov, real_mean, real_cov)\n",
    "\n",
    "        return fid\n",
    "\n",
    "    @staticmethod\n",
    "    def load_patched_inception_v3():\n",
    "        inception = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)\n",
    "        inception.fc = nn.Identity()\n",
    "        return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "  0%|          | 0/62 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/FastGAN/benchmarking/images\n",
      "/home/jovyan/FastGAN/eval_40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 1 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 2 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 3 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 4 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Number of synthetic images: 2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 1 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 2 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 3 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 4 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 5 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 6 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 7 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 8 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 9 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 10 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 11 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 12 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 13 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 14 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 15 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 16 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 17 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 18 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 19 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 21 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 22 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 23 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 24 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 25 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 26 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 27 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 28 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 29 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 30 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 31 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 32 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 33 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 34 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 35 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 36 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 37 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 38 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 39 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 40 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 41 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 42 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 43 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 44 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 45 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 46 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 47 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 48 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 49 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 50 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 51 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 52 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 53 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 54 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 55 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 56 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 57 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 58 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 59 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "Batch 61 - Data shape: torch.Size([32, 3, 256, 256]), Target shape: torch.Size([32])\n",
      "fid score: 1.6408695886198288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_a = os.path.join(os.getcwd(), 'images')\n",
    "print (path_a)\n",
    "path_b = os.path.join('/home', 'jovyan', 'FastGAN', 'eval_40000')\n",
    "print (path_b)\n",
    "fid = FIDScore(path_a, path_b, 256, 32)\n",
    "fid_score = fid()\n",
    "print ('fid score:' , fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print (torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
