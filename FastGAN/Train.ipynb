{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "seq = nn.Sequential\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        try:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        except:\n",
    "            pass\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def conv2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.Conv2d(*args, **kwargs))\n",
    "\n",
    "def convTranspose2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.ConvTranspose2d(*args, **kwargs))\n",
    "\n",
    "def batchNorm2d(*args, **kwargs):\n",
    "    return nn.BatchNorm2d(*args, **kwargs)\n",
    "\n",
    "def linear(*args, **kwargs):\n",
    "    return spectral_norm(nn.Linear(*args, **kwargs))\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input * torch.rsqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.target_shape = shape\n",
    "\n",
    "    def forward(self, feat):\n",
    "        batch = feat.shape[0]\n",
    "        return feat.view(batch, *self.target_shape)        \n",
    "\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        nc = x.size(1)\n",
    "        assert nc % 2 == 0, 'channels dont divide 2!'\n",
    "        nc = int(nc/2)\n",
    "        return x[:, :nc] * torch.sigmoid(x[:, nc:])\n",
    "\n",
    "\n",
    "class NoiseInjection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, feat, noise=None):\n",
    "        if noise is None:\n",
    "            batch, _, height, width = feat.shape\n",
    "            noise = torch.randn(batch, 1, height, width).to(feat.device)\n",
    "\n",
    "        return feat + self.weight * noise\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, feat):\n",
    "        return feat * torch.sigmoid(feat)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(4), \n",
    "                                    conv2d(ch_in, ch_out, 4, 1, 0, bias=False), Swish(),\n",
    "                                    conv2d(ch_out, ch_out, 1, 1, 0, bias=False), nn.Sigmoid() )\n",
    "\n",
    "    def forward(self, feat_small, feat_big):\n",
    "        return feat_big * self.main(feat_small)\n",
    "\n",
    "\n",
    "class InitLayer(nn.Module):\n",
    "    def __init__(self, nz, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "                        convTranspose2d(nz, channel*2, 4, 1, 0, bias=False),\n",
    "                        batchNorm2d(channel*2), GLU() )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1, 1, 1)\n",
    "        return self.init(noise)\n",
    "\n",
    "\n",
    "def UpBlock(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        batchNorm2d(out_planes*2), GLU())\n",
    "    return block\n",
    "\n",
    "\n",
    "def UpBlockComp(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU(),\n",
    "        conv2d(out_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU()\n",
    "        )\n",
    "    return block\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf=64, nz=100, nc=3, im_size=1024):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ngf)\n",
    "\n",
    "        self.im_size = im_size\n",
    "\n",
    "        self.init = InitLayer(nz, channel=nfc[4])\n",
    "                                \n",
    "        self.feat_8   = UpBlockComp(nfc[4], nfc[8])\n",
    "        self.feat_16  = UpBlock(nfc[8], nfc[16])\n",
    "        self.feat_32  = UpBlockComp(nfc[16], nfc[32])\n",
    "        self.feat_64  = UpBlock(nfc[32], nfc[64])\n",
    "        self.feat_128 = UpBlockComp(nfc[64], nfc[128])  \n",
    "        self.feat_256 = UpBlock(nfc[128], nfc[256]) \n",
    "\n",
    "        self.se_64  = SEBlock(nfc[4], nfc[64])\n",
    "        self.se_128 = SEBlock(nfc[8], nfc[128])\n",
    "        self.se_256 = SEBlock(nfc[16], nfc[256])\n",
    "\n",
    "        self.to_128 = conv2d(nfc[128], nc, 1, 1, 0, bias=False) \n",
    "        self.to_big = conv2d(nfc[im_size], nc, 3, 1, 1, bias=False) \n",
    "        \n",
    "        if im_size > 256:\n",
    "            self.feat_512 = UpBlockComp(nfc[256], nfc[512]) \n",
    "            self.se_512 = SEBlock(nfc[32], nfc[512])\n",
    "        if im_size > 512:\n",
    "            self.feat_1024 = UpBlock(nfc[512], nfc[1024])  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        feat_4   = self.init(input)\n",
    "        feat_8   = self.feat_8(feat_4)\n",
    "        feat_16  = self.feat_16(feat_8)\n",
    "        feat_32  = self.feat_32(feat_16)\n",
    "\n",
    "        feat_64  = self.se_64( feat_4, self.feat_64(feat_32) )\n",
    "\n",
    "        feat_128 = self.se_128( feat_8, self.feat_128(feat_64) )\n",
    "\n",
    "        feat_256 = self.se_256( feat_16, self.feat_256(feat_128) )\n",
    "\n",
    "        if self.im_size == 256:\n",
    "            return [self.to_big(feat_256), self.to_128(feat_128)]\n",
    "        \n",
    "        feat_512 = self.se_512( feat_32, self.feat_512(feat_256) )\n",
    "        if self.im_size == 512:\n",
    "            return [self.to_big(feat_512), self.to_128(feat_128)]\n",
    "\n",
    "        feat_1024 = self.feat_1024(feat_512)\n",
    "\n",
    "        im_128 = torch.tanh(self.to_128(feat_128))\n",
    "        im_1024 = torch.tanh(self.to_big(feat_1024))\n",
    "\n",
    "        return [im_1024, im_128]\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlock, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return self.main(feat)\n",
    "\n",
    "\n",
    "class DownBlockComp(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlockComp, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            conv2d(out_planes, out_planes, 3, 1, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        self.direct = nn.Sequential(\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            conv2d(in_planes, out_planes, 1, 1, 0, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return (self.main(feat) + self.direct(feat)) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:16, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        if im_size == 1024:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[1024], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    conv2d(nfc[1024], nfc[512], 4, 2, 1, bias=False),\n",
    "                                    batchNorm2d(nfc[512]),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        elif im_size == 512:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "        elif im_size == 256:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 3, 1, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "\n",
    "        self.down_4  = DownBlockComp(nfc[512], nfc[256])\n",
    "        self.down_8  = DownBlockComp(nfc[256], nfc[128])\n",
    "        self.down_16 = DownBlockComp(nfc[128], nfc[64])\n",
    "        self.down_32 = DownBlockComp(nfc[64],  nfc[32])\n",
    "        self.down_64 = DownBlockComp(nfc[32],  nfc[16])\n",
    "\n",
    "        self.rf_big = nn.Sequential(\n",
    "                            conv2d(nfc[16] , nfc[8], 1, 1, 0, bias=False),\n",
    "                            batchNorm2d(nfc[8]), nn.LeakyReLU(0.2, inplace=True),\n",
    "                            conv2d(nfc[8], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.se_2_16 = SEBlock(nfc[512], nfc[64])\n",
    "        self.se_4_32 = SEBlock(nfc[256], nfc[32])\n",
    "        self.se_8_64 = SEBlock(nfc[128], nfc[16])\n",
    "        \n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "\n",
    "        self.rf_small = conv2d(nfc[32], 1, 4, 1, 0, bias=False)\n",
    "\n",
    "        self.decoder_big = SimpleDecoder(nfc[16], nc)\n",
    "        self.decoder_part = SimpleDecoder(nfc[32], nc)\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, imgs, label, part=None):\n",
    "        if type(imgs) is not list:\n",
    "            imgs = [F.interpolate(imgs, size=self.im_size), F.interpolate(imgs, size=128)]\n",
    "\n",
    "        feat_2 = self.down_from_big(imgs[0])        \n",
    "        feat_4 = self.down_4(feat_2)\n",
    "        feat_8 = self.down_8(feat_4)\n",
    "        \n",
    "        feat_16 = self.down_16(feat_8)\n",
    "        feat_16 = self.se_2_16(feat_2, feat_16)\n",
    "\n",
    "        feat_32 = self.down_32(feat_16)\n",
    "        feat_32 = self.se_4_32(feat_4, feat_32)\n",
    "        \n",
    "        feat_last = self.down_64(feat_32)\n",
    "        feat_last = self.se_8_64(feat_8, feat_last)\n",
    "\n",
    "        #rf_0 = torch.cat([self.rf_big_1(feat_last).view(-1),self.rf_big_2(feat_last).view(-1)])\n",
    "        #rff_big = torch.sigmoid(self.rf_factor_big)\n",
    "        rf_0 = self.rf_big(feat_last).view(-1)\n",
    "\n",
    "        feat_small = self.down_from_small(imgs[1])\n",
    "        #rf_1 = torch.cat([self.rf_small_1(feat_small).view(-1),self.rf_small_2(feat_small).view(-1)])\n",
    "        rf_1 = self.rf_small(feat_small).view(-1)\n",
    "\n",
    "        if label=='real':    \n",
    "            rec_img_big = self.decoder_big(feat_last)\n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            assert part is not None\n",
    "            rec_img_part = None\n",
    "            if part==0:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,:8])\n",
    "            if part==1:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,8:])\n",
    "            if part==2:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,:8])\n",
    "            if part==3:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,8:])\n",
    "\n",
    "            return torch.cat([rf_0, rf_1]) , [rec_img_big, rec_img_small, rec_img_part]\n",
    "\n",
    "        return torch.cat([rf_0, rf_1]) \n",
    "\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    \"\"\"docstring for CAN_SimpleDecoder\"\"\"\n",
    "    def __init__(self, nfc_in=64, nc=3):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*32)\n",
    "\n",
    "        def upBlock(in_planes, out_planes):\n",
    "            block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "                batchNorm2d(out_planes*2), GLU())\n",
    "            return block\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(8),\n",
    "                                    upBlock(nfc_in, nfc[16]) ,\n",
    "                                    upBlock(nfc[16], nfc[32]),\n",
    "                                    upBlock(nfc[32], nfc[64]),\n",
    "                                    upBlock(nfc[64], nfc[128]),\n",
    "                                    conv2d(nfc[128], nc, 3, 1, 1, bias=False),\n",
    "                                    nn.Tanh() )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape: c x 4 x 4\n",
    "        return self.main(input)\n",
    "\n",
    "from random import randint\n",
    "def random_crop(image, size):\n",
    "    h, w = image.shape[2:]\n",
    "    ch = randint(0, h-size-1)\n",
    "    cw = randint(0, w-size-1)\n",
    "    return image[:,:,ch:ch+size,cw:cw+size]\n",
    "\n",
    "class TextureDiscriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(TextureDiscriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "        self.rf_small = nn.Sequential(\n",
    "                            conv2d(nfc[16], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, img, label):\n",
    "        img = random_crop(img, size=128)\n",
    "\n",
    "        feat_small = self.down_from_small(img)\n",
    "        rf = self.rf_small(feat_small).view(-1)\n",
    "        \n",
    "        if label=='real':    \n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            return rf, rec_img_small, img\n",
    "\n",
    "        return rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "def InfiniteSampler(n):\n",
    "    \"\"\"Data sampler\"\"\"\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    \"\"\"Data sampler wrapper\"\"\"\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31\n",
    "\n",
    "\n",
    "def copy_G_params(model):\n",
    "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
    "    return flatten\n",
    "    \n",
    "\n",
    "def load_params(model, new_param):\n",
    "    for p, new_p in zip(model.parameters(), new_param):\n",
    "        p.data.copy_(new_p)\n",
    "\n",
    "\n",
    "def get_dir(args):\n",
    "    task_name = 'train_results/' + args.name\n",
    "    saved_model_folder = os.path.join( task_name, 'models')\n",
    "    saved_image_folder = os.path.join( task_name, 'images')\n",
    "    \n",
    "    os.makedirs(saved_model_folder, exist_ok=True)\n",
    "    os.makedirs(saved_image_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    for f in os.listdir('./'):\n",
    "        if '.py' in f:\n",
    "            shutil.copy(f, task_name+'/'+f)\n",
    "    \n",
    "    with open( os.path.join(saved_model_folder, '../args.txt'), 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)\n",
    "\n",
    "    return saved_model_folder, saved_image_folder\n",
    "\n",
    "\n",
    "class  ImageFolder(Dataset):\n",
    "    \"\"\"docstring for ArtDataset\"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        super( ImageFolder, self).__init__()\n",
    "        self.root = root\n",
    "\n",
    "        self.frame = self._parse_frame()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _parse_frame(self):\n",
    "        frame = []\n",
    "        img_names = os.listdir(self.root)\n",
    "        img_names.sort()\n",
    "        for i in range(len(img_names)):\n",
    "            image_path = os.path.join(self.root, img_names[i])\n",
    "            if image_path[-4:] == '.jpg' or image_path[-4:] == '.png' or image_path[-5:] == '.jpeg': \n",
    "                frame.append(image_path)\n",
    "        return frame\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.frame[idx]\n",
    "        img = Image.open(file).convert('RGB')\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img) \n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "import lmdb\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MultiResolutionDataset(Dataset):\n",
    "    def __init__(self, path, transform, resolution=256):\n",
    "        self.env = lmdb.open(\n",
    "            path,\n",
    "            max_readers=32,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "        )\n",
    "\n",
    "        if not self.env:\n",
    "            raise IOError('Cannot open lmdb dataset', path)\n",
    "\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
    "\n",
    "        self.resolution = resolution\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            key = f'{self.resolution}-{str(index).zfill(5)}'.encode('utf-8')\n",
    "            img_bytes = txn.get(key)\n",
    "            #key_asp = f'aspect_ratio-{str(index).zfill(5)}'.encode('utf-8')\n",
    "            #aspect_ratio = float(txn.get(key_asp).decode())\n",
    "\n",
    "        buffer = BytesIO(img_bytes)\n",
    "        img = Image.open(buffer)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/NN/datasets/BV/img\n",
      "{'path': '/home/jovyan/NN/datasets/BV/img', 'cuda': 0, 'name': 'test_bv_256', 'iter': 100000, 'start_iter': 0, 'batch_size': 1, 'im_size': 256, 'ckpt': 'None', 'noise_dim': 400, 'fid_batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "  0%|          | 0/100001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: -0.06127    loss g: -1.12941\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "  0%|          | 1/100001 [00:21<608:52:45, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 5.224418162935107\n",
      "Fid scores: [5.224418162935107]\n",
      "New min fid score: 5.224418162935\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/100001 [00:32<3:05:20,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.09340    loss g: -1.94370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 203/100001 [00:43<2:56:43,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.97000    loss g: -3.40460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 303/100001 [00:54<2:55:34,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.04327    loss g: -2.26619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 401/100001 [01:05<3:02:48,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.43738    loss g: -2.81782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 501/100001 [01:16<3:09:00,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.43005    loss g: -2.89909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 601/100001 [01:26<3:02:53,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.93361    loss g: -3.34351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 701/100001 [01:37<3:04:38,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.68156    loss g: -4.03175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 801/100001 [01:48<3:06:41,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.77689    loss g: -3.35505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 903/100001 [01:59<2:55:29,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.68215    loss g: -2.17684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1000/100001 [02:10<3:00:26,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.37672    loss g: -2.59872\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.7267402617327505\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505]\n",
      "New min fid score: 2.726740261733\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1101/100001 [02:45<3:03:42,  8.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.96387    loss g: -3.48069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1201/100001 [02:56<3:04:53,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 4.08081    loss g: -2.16724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1301/100001 [03:06<3:04:13,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.92971    loss g: -2.61662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1401/100001 [03:17<3:00:27,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.16112    loss g: -2.75913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1501/100001 [03:28<3:02:09,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.26383    loss g: -2.75104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1601/100001 [03:39<3:04:43,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.80683    loss g: -2.56858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1701/100001 [03:50<3:05:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.11285    loss g: -2.12801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1801/100001 [04:00<3:01:05,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.80600    loss g: -2.39804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1902/100001 [04:11<2:57:31,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.73035    loss g: -2.15833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/100001 [04:22<2:54:32,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.55222    loss g: -2.62199\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2002/100001 [04:44<125:27:49,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.99193364529928\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]3:48,  9.39it/s]  \n",
      "  0%|          | 0/15 [00:06<?, ?it/s]\n",
      "  2%|▏         | 2102/100001 [04:54<3:00:20,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.59263    loss g: -2.91206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2203/100001 [05:05<2:52:42,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.42436    loss g: -2.98949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2301/100001 [05:16<3:02:11,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.87436    loss g: -2.52295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2401/100001 [05:26<2:59:58,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.31111    loss g: -2.09345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2501/100001 [05:37<3:04:06,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.67742    loss g: -2.37808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2601/100001 [05:48<3:04:43,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.51048    loss g: -2.15211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2691/100001 [05:58<2:51:47,  9.44it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import utils as vutils\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from scipy import linalg\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "from diffaug import DiffAugment\n",
    "\n",
    "policy = 'color,translation'\n",
    "\n",
    "\n",
    "class FIDScore:\n",
    "    def __init__(self, path_a, path_b, image_size, batch_size, device='cuda'):\n",
    "        self.device = device\n",
    "        self.image_size = image_size\n",
    "        self.path_a = path_a\n",
    "        self.path_b = path_b\n",
    "        self.batch_size = batch_size\n",
    "        self.inception = self.load_patched_inception_v3().eval().to(device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, loader):\n",
    "        #for batch_idx, batch_data in enumerate(loader):\n",
    "            #print(f\"Batch {batch_idx} - Batch shape: {batch_data.shape}, Batch contents: {batch_data}\")\n",
    "        pbar = tqdm(loader)\n",
    "        feature_list = []\n",
    "        for img in loader:\n",
    "            img = img.to(self.device)\n",
    "            feature = self.inception(img)[0].view(img.shape[0], -1)\n",
    "            feature_list.append(feature.to('cpu'))\n",
    "        features = torch.cat(feature_list, 0)\n",
    "        return features\n",
    "\n",
    "    def calc_fid(self, sample_mean, sample_cov, real_mean, real_cov, eps=1e-6):\n",
    "        cov_sqrt, _ = linalg.sqrtm(sample_cov @ real_cov, disp=False)\n",
    "        if not np.isfinite(cov_sqrt).all():\n",
    "            print('product of cov matrices is singular')\n",
    "            offset = np.eye(sample_cov.shape[0]) * eps\n",
    "            cov_sqrt = linalg.sqrtm((sample_cov + offset) @ (real_cov + offset))\n",
    "        if np.iscomplexobj(cov_sqrt):\n",
    "            if not np.allclose(np.diagonal(cov_sqrt).imag, 0, atol=1e-3):\n",
    "                m = np.max(np.abs(cov_sqrt.imag))\n",
    "                raise ValueError(f'Imaginary component {m}')\n",
    "            cov_sqrt = cov_sqrt.real\n",
    "        mean_diff = sample_mean - real_mean\n",
    "        mean_norm = mean_diff @ mean_diff\n",
    "        trace = np.trace(sample_cov) + np.trace(real_cov) - 2 * np.trace(cov_sqrt)\n",
    "        fid = mean_norm + trace\n",
    "        return fid\n",
    "\n",
    "    def __call__(self, num_workers=4):\n",
    "        dset_a = ImageFolder(self.path_a, self.transform)\n",
    "        print(\"Number of real images:\", len(dset_a))\n",
    "        loader_a = DataLoader(dset_a, batch_size=self.batch_size, num_workers=num_workers, drop_last=True)\n",
    "        features_a = self.extract_features(loader_a).numpy()\n",
    "        real_mean = np.mean(features_a, 0)\n",
    "        real_cov = np.cov(features_a, rowvar=False)\n",
    "\n",
    "        dset_b = ImageFolder(self.path_b, self.transform)\n",
    "        print(\"Number of synthetic images:\", len(dset_b))\n",
    "        loader_b = DataLoader(dset_b, batch_size=self.batch_size, num_workers=num_workers, drop_last=True)\n",
    "        features_b = self.extract_features(loader_b).numpy()\n",
    "        sample_mean = np.mean(features_b, 0)\n",
    "        sample_cov = np.cov(features_b, rowvar=False)\n",
    "\n",
    "        fid = self.calc_fid(sample_mean, sample_cov, real_mean, real_cov)\n",
    "\n",
    "        return fid\n",
    "\n",
    "    @staticmethod\n",
    "    def load_patched_inception_v3():\n",
    "        inception = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)\n",
    "        inception.fc = nn.Identity()\n",
    "        return inception\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def crop_image_by_part(image, part):\n",
    "    hw = image.shape[2] // 2\n",
    "    if part == 0:\n",
    "        return image[:, :, :hw, :hw]\n",
    "    if part == 1:\n",
    "        return image[:, :, :hw, hw:]\n",
    "    if part == 2:\n",
    "        return image[:, :, hw:, :hw]\n",
    "    if part == 3:\n",
    "        return image[:, :, hw:, hw:]\n",
    "\n",
    "\n",
    "def train_d(net, data, label=\"real\"):\n",
    "    \"\"\"Train function of discriminator\"\"\"\n",
    "    if label == \"real\":\n",
    "        part = random.randint(0, 3)\n",
    "        pred, [rec_all, rec_small, rec_part] = net(data, label, part=part)\n",
    "        err = F.relu(torch.rand_like(pred) * 0.2 + 0.8 - pred).mean()\n",
    "        err.backward()\n",
    "        return pred.mean().item(), rec_all, rec_small, rec_part\n",
    "    else:\n",
    "        pred = net(data, label)\n",
    "        err = F.relu(torch.rand_like(pred) * 0.2 + 0.8 + pred).mean()\n",
    "        err.backward()\n",
    "        return pred.mean().item()\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    data_root = args.path\n",
    "    total_iterations = args.iter\n",
    "    checkpoint = args.ckpt\n",
    "    batch_size = args.batch_size\n",
    "    im_size = args.im_size\n",
    "    ndf = 64\n",
    "    ngf = 64\n",
    "    nz = args.noise_dim\n",
    "    nlr = 0.0001\n",
    "    nbeta1 = 0.5\n",
    "    use_cuda = True\n",
    "    multi_gpu = True\n",
    "    dataloader_workers = 8\n",
    "    current_iteration = args.start_iter\n",
    "    save_interval = 100\n",
    "    saved_model_folder, saved_image_folder = get_dir(args)\n",
    "    fid_batch_size = args.fid_batch_size\n",
    "    save_results_dir = args.name\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "\n",
    "    transform_list = [\n",
    "        transforms.Resize((int(im_size), int(im_size))),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    trans = transforms.Compose(transform_list)\n",
    "\n",
    "    if 'lmdb' in data_root:\n",
    "        from operation import MultiResolutionDataset\n",
    "        dataset = MultiResolutionDataset(data_root, trans, 1024)\n",
    "    else:\n",
    "        dataset = ImageFolder(root=data_root, transform=trans)\n",
    "\n",
    "    dataloader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                                 sampler=InfiniteSamplerWrapper(dataset), num_workers=dataloader_workers,\n",
    "                                 pin_memory=True))\n",
    "    '''\n",
    "    loader = MultiEpochsDataLoader(dataset, batch_size=batch_size, \n",
    "                               shuffle=True, num_workers=dataloader_workers, \n",
    "                               pin_memory=True)\n",
    "    dataloader = CudaDataLoader(loader, 'cuda')\n",
    "    '''\n",
    "\n",
    "    # from model_s import Generator, Discriminator\n",
    "    netG = Generator(ngf=ngf, nz=nz, im_size=im_size)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    netD = Discriminator(ndf=ndf, im_size=im_size)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    netG.to(device)\n",
    "    netD.to(device)\n",
    "\n",
    "    avg_param_G = copy_G_params(netG)\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n",
    "    \n",
    "    generated_images = os.path.join(os.getcwd(), 'train_results', save_results_dir, \"images\")    \n",
    "    fid = FIDScore(data_root, generated_images, im_size, fid_batch_size)\n",
    "    fid_scores = []\n",
    "    min_fid_score = 999\n",
    "\n",
    "    if checkpoint != 'None':\n",
    "        ckpt = torch.load(checkpoint)\n",
    "        netG.load_state_dict({k.replace('module.', ''): v for k, v in ckpt['g'].items()})\n",
    "        netD.load_state_dict({k.replace('module.', ''): v for k, v in ckpt['d'].items()})\n",
    "        avg_param_G = ckpt['g_ema']\n",
    "        optimizerG.load_state_dict(ckpt['opt_g'])\n",
    "        optimizerD.load_state_dict(ckpt['opt_d'])\n",
    "        current_iteration = int(checkpoint.split('_')[-1].split('.')[0])\n",
    "        del ckpt\n",
    "\n",
    "    if multi_gpu:\n",
    "        netG = nn.DataParallel(netG.to(device))\n",
    "        netD = nn.DataParallel(netD.to(device))\n",
    "\n",
    "    for iteration in tqdm(range(current_iteration, total_iterations + 1)):\n",
    "        real_image = next(dataloader)\n",
    "        real_image = real_image.to(device)\n",
    "        current_batch_size = real_image.size(0)\n",
    "        noise = torch.Tensor(current_batch_size, nz).normal_(0, 1).to(device)\n",
    "\n",
    "        fake_images = netG(noise)\n",
    "\n",
    "        real_image = DiffAugment(real_image, policy=policy)\n",
    "        fake_images = [DiffAugment(fake, policy=policy) for fake in fake_images]\n",
    "\n",
    "        ## 2. train Discriminator\n",
    "        netD.zero_grad()\n",
    "\n",
    "        err_dr, rec_img_all, rec_img_small, rec_img_part = train_d(netD, real_image, label=\"real\")\n",
    "        train_d(netD, [fi.detach() for fi in fake_images], label=\"fake\")\n",
    "        optimizerD.step()\n",
    "\n",
    "        ## 3. train Generator\n",
    "        netG.zero_grad()\n",
    "        pred_g = netD(fake_images, \"fake\")\n",
    "        err_g = -pred_g.mean()\n",
    "\n",
    "        err_g.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        for p, avg_p in zip(netG.parameters(), avg_param_G):\n",
    "            avg_p.mul_(0.999).add_(0.001 * p.data)\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(\"GAN: loss d: %.5f    loss g: %.5f\" % (err_dr, -err_g.item()))\n",
    "\n",
    "        \n",
    "        if iteration % (save_interval * 10) == 0 or iteration == total_iterations:\n",
    "            backup_para = copy_G_params(netG)\n",
    "            load_params(netG, avg_param_G)\n",
    "            print (\"saving current model\")\n",
    "            torch.save({'g': netG.state_dict(), 'd': netD.state_dict()}, saved_model_folder + '/last_model.pth')\n",
    "            with torch.no_grad():\n",
    "                for i in range (500):\n",
    "                    fixed_noise = torch.FloatTensor(1, nz).normal_(0, 1).to(device)\n",
    "                    generated_images = netG(fixed_noise)                \n",
    "                    #print(\"saved %d image\" % i)\n",
    "                    vutils.save_image(generated_images[0].add(1).mul(0.5), saved_image_folder + '/%d.jpg' % i)\n",
    "\n",
    "            fid_score = fid()\n",
    "            fid_scores.append(fid_score)\n",
    "            print ('Current fid score:' , fid_score)\n",
    "            print ('Fid scores:' , fid_scores)\n",
    "            \n",
    "            fid_results_path = os.path.join(os.getcwd(), 'train_results', save_results_dir, \"fid.txt\")    \n",
    "\n",
    "            with open(fid_results_path, 'w') as file:\n",
    "                for value in fid_scores:\n",
    "                    file.write(str(value) + '\\n')\n",
    "            \n",
    "            if fid_score < min_fid_score:\n",
    "                min_fid_score = fid_score\n",
    "                print('New min fid score: %.12f' % fid_score)\n",
    "                print('Saving best model')\n",
    "                torch.save({'g': netG.state_dict(), 'd': netD.state_dict()}, saved_model_folder + '/min_fid_model.pth')\n",
    "                #load_params(netG, backup_para)\n",
    "                #torch.save({'g': netG.state_dict(), 'd': netD.state_dict(), 'g_ema': avg_param_G, 'opt_g': optimizerG.state_dict(), 'opt_d': optimizerD.state_dict()}, saved_model_folder + '/all_%d.pth' % iteration)\n",
    "\n",
    "            load_params(netG, backup_para)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #data_root = os.path.join(os.path.abspath('..'), \"datasets\", \"drive\", \"img\")\n",
    "    data_root = os.path.join(os.path.abspath('..'), \"datasets\", \"BV\", \"img\")\n",
    "    print (data_root)\n",
    "    args = easydict.EasyDict({\n",
    "        \"path\": data_root,\n",
    "        \"cuda\": 0,\n",
    "        \"name\": 'test_bv_256',\n",
    "        \"iter\": 100000,\n",
    "        \"start_iter\": 0, \n",
    "        \"batch_size\": 1,\n",
    "        \"im_size\": 256,\n",
    "        \"ckpt\": 'None',\n",
    "        \"noise_dim\": 400,\n",
    "        \"fid_batch_size\": 32\n",
    "    })\n",
    "    \n",
    "    print(args)\n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
