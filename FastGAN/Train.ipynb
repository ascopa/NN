{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "seq = nn.Sequential\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        try:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        except:\n",
    "            pass\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def conv2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.Conv2d(*args, **kwargs))\n",
    "\n",
    "def convTranspose2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.ConvTranspose2d(*args, **kwargs))\n",
    "\n",
    "def batchNorm2d(*args, **kwargs):\n",
    "    return nn.BatchNorm2d(*args, **kwargs)\n",
    "\n",
    "def linear(*args, **kwargs):\n",
    "    return spectral_norm(nn.Linear(*args, **kwargs))\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input * torch.rsqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.target_shape = shape\n",
    "\n",
    "    def forward(self, feat):\n",
    "        batch = feat.shape[0]\n",
    "        return feat.view(batch, *self.target_shape)        \n",
    "\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        nc = x.size(1)\n",
    "        assert nc % 2 == 0, 'channels dont divide 2!'\n",
    "        nc = int(nc/2)\n",
    "        return x[:, :nc] * torch.sigmoid(x[:, nc:])\n",
    "\n",
    "\n",
    "class NoiseInjection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, feat, noise=None):\n",
    "        if noise is None:\n",
    "            batch, _, height, width = feat.shape\n",
    "            noise = torch.randn(batch, 1, height, width).to(feat.device)\n",
    "\n",
    "        return feat + self.weight * noise\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, feat):\n",
    "        return feat * torch.sigmoid(feat)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(4), \n",
    "                                    conv2d(ch_in, ch_out, 4, 1, 0, bias=False), Swish(),\n",
    "                                    conv2d(ch_out, ch_out, 1, 1, 0, bias=False), nn.Sigmoid() )\n",
    "\n",
    "    def forward(self, feat_small, feat_big):\n",
    "        return feat_big * self.main(feat_small)\n",
    "\n",
    "\n",
    "class InitLayer(nn.Module):\n",
    "    def __init__(self, nz, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "                        convTranspose2d(nz, channel*2, 4, 1, 0, bias=False),\n",
    "                        batchNorm2d(channel*2), GLU() )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1, 1, 1)\n",
    "        return self.init(noise)\n",
    "\n",
    "\n",
    "def UpBlock(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        batchNorm2d(out_planes*2), GLU())\n",
    "    return block\n",
    "\n",
    "\n",
    "def UpBlockComp(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU(),\n",
    "        conv2d(out_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU()\n",
    "        )\n",
    "    return block\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf=64, nz=100, nc=3, im_size=1024):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ngf)\n",
    "\n",
    "        self.im_size = im_size\n",
    "\n",
    "        self.init = InitLayer(nz, channel=nfc[4])\n",
    "                                \n",
    "        self.feat_8   = UpBlockComp(nfc[4], nfc[8])\n",
    "        self.feat_16  = UpBlock(nfc[8], nfc[16])\n",
    "        self.feat_32  = UpBlockComp(nfc[16], nfc[32])\n",
    "        self.feat_64  = UpBlock(nfc[32], nfc[64])\n",
    "        self.feat_128 = UpBlockComp(nfc[64], nfc[128])  \n",
    "        self.feat_256 = UpBlock(nfc[128], nfc[256]) \n",
    "\n",
    "        self.se_64  = SEBlock(nfc[4], nfc[64])\n",
    "        self.se_128 = SEBlock(nfc[8], nfc[128])\n",
    "        self.se_256 = SEBlock(nfc[16], nfc[256])\n",
    "\n",
    "        self.to_128 = conv2d(nfc[128], nc, 1, 1, 0, bias=False) \n",
    "        self.to_big = conv2d(nfc[im_size], nc, 3, 1, 1, bias=False) \n",
    "        \n",
    "        if im_size > 256:\n",
    "            self.feat_512 = UpBlockComp(nfc[256], nfc[512]) \n",
    "            self.se_512 = SEBlock(nfc[32], nfc[512])\n",
    "        if im_size > 512:\n",
    "            self.feat_1024 = UpBlock(nfc[512], nfc[1024])  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        feat_4   = self.init(input)\n",
    "        feat_8   = self.feat_8(feat_4)\n",
    "        feat_16  = self.feat_16(feat_8)\n",
    "        feat_32  = self.feat_32(feat_16)\n",
    "\n",
    "        feat_64  = self.se_64( feat_4, self.feat_64(feat_32) )\n",
    "\n",
    "        feat_128 = self.se_128( feat_8, self.feat_128(feat_64) )\n",
    "\n",
    "        feat_256 = self.se_256( feat_16, self.feat_256(feat_128) )\n",
    "\n",
    "        if self.im_size == 256:\n",
    "            return [self.to_big(feat_256), self.to_128(feat_128)]\n",
    "        \n",
    "        feat_512 = self.se_512( feat_32, self.feat_512(feat_256) )\n",
    "        if self.im_size == 512:\n",
    "            return [self.to_big(feat_512), self.to_128(feat_128)]\n",
    "\n",
    "        feat_1024 = self.feat_1024(feat_512)\n",
    "\n",
    "        im_128 = torch.tanh(self.to_128(feat_128))\n",
    "        im_1024 = torch.tanh(self.to_big(feat_1024))\n",
    "\n",
    "        return [im_1024, im_128]\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlock, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return self.main(feat)\n",
    "\n",
    "\n",
    "class DownBlockComp(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlockComp, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            conv2d(out_planes, out_planes, 3, 1, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        self.direct = nn.Sequential(\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            conv2d(in_planes, out_planes, 1, 1, 0, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return (self.main(feat) + self.direct(feat)) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:16, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        if im_size == 1024:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[1024], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    conv2d(nfc[1024], nfc[512], 4, 2, 1, bias=False),\n",
    "                                    batchNorm2d(nfc[512]),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        elif im_size == 512:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "        elif im_size == 256:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 3, 1, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "\n",
    "        self.down_4  = DownBlockComp(nfc[512], nfc[256])\n",
    "        self.down_8  = DownBlockComp(nfc[256], nfc[128])\n",
    "        self.down_16 = DownBlockComp(nfc[128], nfc[64])\n",
    "        self.down_32 = DownBlockComp(nfc[64],  nfc[32])\n",
    "        self.down_64 = DownBlockComp(nfc[32],  nfc[16])\n",
    "\n",
    "        self.rf_big = nn.Sequential(\n",
    "                            conv2d(nfc[16] , nfc[8], 1, 1, 0, bias=False),\n",
    "                            batchNorm2d(nfc[8]), nn.LeakyReLU(0.2, inplace=True),\n",
    "                            conv2d(nfc[8], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.se_2_16 = SEBlock(nfc[512], nfc[64])\n",
    "        self.se_4_32 = SEBlock(nfc[256], nfc[32])\n",
    "        self.se_8_64 = SEBlock(nfc[128], nfc[16])\n",
    "        \n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "\n",
    "        self.rf_small = conv2d(nfc[32], 1, 4, 1, 0, bias=False)\n",
    "\n",
    "        self.decoder_big = SimpleDecoder(nfc[16], nc)\n",
    "        self.decoder_part = SimpleDecoder(nfc[32], nc)\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, imgs, label, part=None):\n",
    "        if type(imgs) is not list:\n",
    "            imgs = [F.interpolate(imgs, size=self.im_size), F.interpolate(imgs, size=128)]\n",
    "\n",
    "        feat_2 = self.down_from_big(imgs[0])        \n",
    "        feat_4 = self.down_4(feat_2)\n",
    "        feat_8 = self.down_8(feat_4)\n",
    "        \n",
    "        feat_16 = self.down_16(feat_8)\n",
    "        feat_16 = self.se_2_16(feat_2, feat_16)\n",
    "\n",
    "        feat_32 = self.down_32(feat_16)\n",
    "        feat_32 = self.se_4_32(feat_4, feat_32)\n",
    "        \n",
    "        feat_last = self.down_64(feat_32)\n",
    "        feat_last = self.se_8_64(feat_8, feat_last)\n",
    "\n",
    "        #rf_0 = torch.cat([self.rf_big_1(feat_last).view(-1),self.rf_big_2(feat_last).view(-1)])\n",
    "        #rff_big = torch.sigmoid(self.rf_factor_big)\n",
    "        rf_0 = self.rf_big(feat_last).view(-1)\n",
    "\n",
    "        feat_small = self.down_from_small(imgs[1])\n",
    "        #rf_1 = torch.cat([self.rf_small_1(feat_small).view(-1),self.rf_small_2(feat_small).view(-1)])\n",
    "        rf_1 = self.rf_small(feat_small).view(-1)\n",
    "\n",
    "        if label=='real':    \n",
    "            rec_img_big = self.decoder_big(feat_last)\n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            assert part is not None\n",
    "            rec_img_part = None\n",
    "            if part==0:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,:8])\n",
    "            if part==1:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,8:])\n",
    "            if part==2:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,:8])\n",
    "            if part==3:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,8:])\n",
    "\n",
    "            return torch.cat([rf_0, rf_1]) , [rec_img_big, rec_img_small, rec_img_part]\n",
    "\n",
    "        return torch.cat([rf_0, rf_1]) \n",
    "\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    \"\"\"docstring for CAN_SimpleDecoder\"\"\"\n",
    "    def __init__(self, nfc_in=64, nc=3):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*32)\n",
    "\n",
    "        def upBlock(in_planes, out_planes):\n",
    "            block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "                batchNorm2d(out_planes*2), GLU())\n",
    "            return block\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(8),\n",
    "                                    upBlock(nfc_in, nfc[16]) ,\n",
    "                                    upBlock(nfc[16], nfc[32]),\n",
    "                                    upBlock(nfc[32], nfc[64]),\n",
    "                                    upBlock(nfc[64], nfc[128]),\n",
    "                                    conv2d(nfc[128], nc, 3, 1, 1, bias=False),\n",
    "                                    nn.Tanh() )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape: c x 4 x 4\n",
    "        return self.main(input)\n",
    "\n",
    "from random import randint\n",
    "def random_crop(image, size):\n",
    "    h, w = image.shape[2:]\n",
    "    ch = randint(0, h-size-1)\n",
    "    cw = randint(0, w-size-1)\n",
    "    return image[:,:,ch:ch+size,cw:cw+size]\n",
    "\n",
    "class TextureDiscriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(TextureDiscriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "        self.rf_small = nn.Sequential(\n",
    "                            conv2d(nfc[16], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, img, label):\n",
    "        img = random_crop(img, size=128)\n",
    "\n",
    "        feat_small = self.down_from_small(img)\n",
    "        rf = self.rf_small(feat_small).view(-1)\n",
    "        \n",
    "        if label=='real':    \n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            return rf, rec_img_small, img\n",
    "\n",
    "        return rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "def InfiniteSampler(n):\n",
    "    \"\"\"Data sampler\"\"\"\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    \"\"\"Data sampler wrapper\"\"\"\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31\n",
    "\n",
    "\n",
    "def copy_G_params(model):\n",
    "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
    "    return flatten\n",
    "    \n",
    "\n",
    "def load_params(model, new_param):\n",
    "    for p, new_p in zip(model.parameters(), new_param):\n",
    "        p.data.copy_(new_p)\n",
    "\n",
    "\n",
    "def get_dir(args):\n",
    "    task_name = 'train_results/' + args.name\n",
    "    saved_model_folder = os.path.join( task_name, 'models')\n",
    "    saved_image_folder = os.path.join( task_name, 'images')\n",
    "    \n",
    "    os.makedirs(saved_model_folder, exist_ok=True)\n",
    "    os.makedirs(saved_image_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    for f in os.listdir('./'):\n",
    "        if '.py' in f:\n",
    "            shutil.copy(f, task_name+'/'+f)\n",
    "    \n",
    "    with open( os.path.join(saved_model_folder, '../args.txt'), 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)\n",
    "\n",
    "    return saved_model_folder, saved_image_folder\n",
    "\n",
    "\n",
    "class  ImageFolder(Dataset):\n",
    "    \"\"\"docstring for ArtDataset\"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        super( ImageFolder, self).__init__()\n",
    "        self.root = root\n",
    "\n",
    "        self.frame = self._parse_frame()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _parse_frame(self):\n",
    "        frame = []\n",
    "        img_names = os.listdir(self.root)\n",
    "        img_names.sort()\n",
    "        for i in range(len(img_names)):\n",
    "            image_path = os.path.join(self.root, img_names[i])\n",
    "            if image_path[-4:] == '.jpg' or image_path[-4:] == '.png' or image_path[-5:] == '.jpeg': \n",
    "                frame.append(image_path)\n",
    "        return frame\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.frame[idx]\n",
    "        img = Image.open(file).convert('RGB')\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img) \n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "import lmdb\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MultiResolutionDataset(Dataset):\n",
    "    def __init__(self, path, transform, resolution=256):\n",
    "        self.env = lmdb.open(\n",
    "            path,\n",
    "            max_readers=32,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "        )\n",
    "\n",
    "        if not self.env:\n",
    "            raise IOError('Cannot open lmdb dataset', path)\n",
    "\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
    "\n",
    "        self.resolution = resolution\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            key = f'{self.resolution}-{str(index).zfill(5)}'.encode('utf-8')\n",
    "            img_bytes = txn.get(key)\n",
    "            #key_asp = f'aspect_ratio-{str(index).zfill(5)}'.encode('utf-8')\n",
    "            #aspect_ratio = float(txn.get(key_asp).decode())\n",
    "\n",
    "        buffer = BytesIO(img_bytes)\n",
    "        img = Image.open(buffer)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/NN/datasets/BV/img\n",
      "{'path': '/home/jovyan/NN/datasets/BV/img', 'cuda': 0, 'name': 'test_bv_256', 'iter': 100000, 'start_iter': 0, 'batch_size': 1, 'im_size': 256, 'ckpt': 'None', 'noise_dim': 400, 'fid_batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "  0%|          | 0/100001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: -0.06127    loss g: -1.12941\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "  0%|          | 1/100001 [00:21<608:52:45, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 5.224418162935107\n",
      "Fid scores: [5.224418162935107]\n",
      "New min fid score: 5.224418162935\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/100001 [00:32<3:05:20,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.09340    loss g: -1.94370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 203/100001 [00:43<2:56:43,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.97000    loss g: -3.40460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 303/100001 [00:54<2:55:34,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.04327    loss g: -2.26619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 401/100001 [01:05<3:02:48,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.43738    loss g: -2.81782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 501/100001 [01:16<3:09:00,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.43005    loss g: -2.89909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 601/100001 [01:26<3:02:53,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.93361    loss g: -3.34351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 701/100001 [01:37<3:04:38,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.68156    loss g: -4.03175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 801/100001 [01:48<3:06:41,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.77689    loss g: -3.35505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 903/100001 [01:59<2:55:29,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.68215    loss g: -2.17684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1000/100001 [02:10<3:00:26,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.37672    loss g: -2.59872\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.7267402617327505\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505]\n",
      "New min fid score: 2.726740261733\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1101/100001 [02:45<3:03:42,  8.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.96387    loss g: -3.48069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1201/100001 [02:56<3:04:53,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 4.08081    loss g: -2.16724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1301/100001 [03:06<3:04:13,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.92971    loss g: -2.61662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1401/100001 [03:17<3:00:27,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.16112    loss g: -2.75913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1501/100001 [03:28<3:02:09,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.26383    loss g: -2.75104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1601/100001 [03:39<3:04:43,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.80683    loss g: -2.56858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1701/100001 [03:50<3:05:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.11285    loss g: -2.12801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1801/100001 [04:00<3:01:05,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.80600    loss g: -2.39804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1902/100001 [04:11<2:57:31,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.73035    loss g: -2.15833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/100001 [04:22<2:54:32,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.55222    loss g: -2.62199\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2002/100001 [04:44<125:27:49,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.99193364529928\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]3:48,  9.39it/s]  \n",
      "  0%|          | 0/15 [00:06<?, ?it/s]\n",
      "  2%|▏         | 2102/100001 [04:54<3:00:20,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.59263    loss g: -2.91206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2203/100001 [05:05<2:52:42,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.42436    loss g: -2.98949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2301/100001 [05:16<3:02:11,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.87436    loss g: -2.52295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2401/100001 [05:26<2:59:58,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.31111    loss g: -2.09345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2501/100001 [05:37<3:04:06,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.67742    loss g: -2.37808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2601/100001 [05:48<3:04:43,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.51048    loss g: -2.15211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2701/100001 [05:59<3:01:33,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.48116    loss g: -2.52679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2801/100001 [06:10<3:03:58,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.31530    loss g: -1.72913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2901/100001 [06:20<3:02:56,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.73672    loss g: -2.28145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3000/100001 [06:31<2:56:29,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.07265    loss g: -1.87778\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3001/100001 [06:53<176:56:32,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.9600639632925656\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:11<?, ?it/s]19:35,  2.72s/it] \n",
      "  0%|          | 0/15 [00:01<?, ?it/s]\n",
      "  3%|▎         | 3101/100001 [07:04<2:58:17,  9.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.12414    loss g: -2.43061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3203/100001 [07:15<2:52:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.85227    loss g: -2.40829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3301/100001 [07:25<3:05:02,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.92551    loss g: -1.91598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3401/100001 [07:36<3:02:18,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.81814    loss g: -2.76012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3501/100001 [07:47<3:00:56,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.56776    loss g: -2.59091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3603/100001 [07:58<2:51:07,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 4.00524    loss g: -2.58627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3702/100001 [08:08<2:52:54,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.99620    loss g: -2.15032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3801/100001 [08:19<3:03:08,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.87646    loss g: -3.07316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3901/100001 [08:30<2:57:09,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.70652    loss g: -2.49506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4000/100001 [08:40<2:53:21,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.04302    loss g: -2.69950\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4001/100001 [09:02<175:18:10,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 3.2043104988962963\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]1:07,  9.34it/s]  \n",
      "  0%|          | 0/15 [00:06<?, ?it/s]\n",
      "  4%|▍         | 4101/100001 [09:13<2:56:15,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.59478    loss g: -3.10008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4203/100001 [09:24<2:48:20,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.35839    loss g: -2.39981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4301/100001 [09:34<2:56:26,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: -0.36067    loss g: -0.65736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4403/100001 [09:45<2:50:07,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.37058    loss g: -0.69211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4501/100001 [09:56<2:56:21,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.62324    loss g: -1.58361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4603/100001 [10:07<2:48:52,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.87159    loss g: -1.53417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4701/100001 [10:18<2:58:47,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.03768    loss g: -1.46121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4801/100001 [10:28<2:53:36,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.17027    loss g: -0.96269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4901/100001 [10:39<2:56:48,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.18593    loss g: -0.35942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5000/100001 [10:50<2:54:50,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.99877    loss g: -1.69725\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  5%|▌         | 5002/100001 [11:12<124:49:42,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 3.387689638897349\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]15:28,  3.34s/it] \n",
      "  0%|          | 0/15 [00:01<?, ?it/s]\n",
      "  5%|▌         | 5101/100001 [11:23<2:53:39,  9.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.17479    loss g: -1.50241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5201/100001 [11:34<2:57:12,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: -0.60848    loss g: -1.15889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5301/100001 [11:44<2:59:25,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.70546    loss g: -1.73622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5401/100001 [11:55<2:58:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.17352    loss g: -1.23408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5501/100001 [12:06<2:55:09,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.30566    loss g: -1.46289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5601/100001 [12:17<2:57:28,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.84648    loss g: -1.67697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5701/100001 [12:28<2:55:37,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.13333    loss g: -1.68451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5801/100001 [12:38<2:56:03,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.28178    loss g: -1.56049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5901/100001 [12:49<2:55:28,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: -0.68663    loss g: -1.42456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6000/100001 [13:00<2:49:40,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.64878    loss g: -1.79255\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6001/100001 [13:22<172:56:32,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 3.2454028512116437\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]9:23,  9.24it/s]  \n",
      "  0%|          | 0/15 [00:07<?, ?it/s]\n",
      "  6%|▌         | 6101/100001 [13:32<2:55:19,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.49228    loss g: -1.65616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6202/100001 [13:43<2:49:56,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.76649    loss g: -1.57122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 6301/100001 [13:54<2:52:24,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.90682    loss g: -1.48733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 6401/100001 [14:05<2:53:34,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.59802    loss g: -1.86740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6501/100001 [14:16<2:58:38,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.63180    loss g: -1.63841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6601/100001 [14:26<2:51:39,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.62438    loss g: -1.61783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6701/100001 [14:37<2:54:43,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.96945    loss g: -1.75268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6801/100001 [14:48<2:52:38,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.78013    loss g: -1.86257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6903/100001 [14:59<2:42:53,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.56493    loss g: -1.67820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7000/100001 [15:09<2:46:36,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.90331    loss g: -1.83748\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7001/100001 [15:31<168:46:24,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 3.2242844127001717\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:14<?, ?it/s]0:45,  9.07it/s]  \n",
      "  0%|          | 0/15 [00:05<?, ?it/s]\n",
      "  7%|▋         | 7101/100001 [15:42<2:52:18,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.07146    loss g: -1.50133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7202/100001 [15:53<2:49:10,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.38597    loss g: -2.39134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7301/100001 [16:03<2:54:21,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.64829    loss g: -1.51666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7401/100001 [16:14<2:54:58,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.28374    loss g: -1.54551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7501/100001 [16:25<2:55:28,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.56266    loss g: -1.89796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7603/100001 [16:36<2:43:01,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.76426    loss g: -1.47621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7701/100001 [16:47<2:55:14,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.16980    loss g: -1.50175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7803/100001 [16:58<2:42:11,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.98943    loss g: -1.83454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7902/100001 [17:08<2:47:01,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 0.19649    loss g: -1.13223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8000/100001 [17:19<2:46:21,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.91268    loss g: -1.91980\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.2907345560428425\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425]\n",
      "New min fid score: 2.290734556043\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 8101/100001 [17:55<2:50:14,  9.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.31592    loss g: -1.80655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8201/100001 [18:05<2:51:17,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.43997    loss g: -1.52594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8302/100001 [18:16<2:46:45,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.41983    loss g: -2.06910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8401/100001 [18:27<2:48:42,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.45798    loss g: -1.69330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 8503/100001 [18:38<2:41:38,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.69855    loss g: -1.68661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 8601/100001 [18:49<2:49:24,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.94051    loss g: -1.52929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 8703/100001 [19:00<2:41:40,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.29238    loss g: -1.56121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8803/100001 [19:10<2:41:49,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.02786    loss g: -1.60531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8901/100001 [19:21<2:48:52,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.86126    loss g: -1.06545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9000/100001 [19:32<2:41:05,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.80957    loss g: -1.70435\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 1.4905136751897707\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707]\n",
      "New min fid score: 1.490513675190\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 9101/100001 [20:08<2:49:05,  8.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.66594    loss g: -1.99668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9203/100001 [20:19<2:38:37,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.68096    loss g: -1.56004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9301/100001 [20:29<2:49:06,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.70629    loss g: -1.72494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9403/100001 [20:40<2:41:10,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.19722    loss g: -1.78425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9501/100001 [20:51<2:49:35,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.15035    loss g: -1.69195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9601/100001 [21:02<2:46:02,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.67746    loss g: -1.66332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9701/100001 [21:12<2:47:36,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.13300    loss g: -1.46437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9803/100001 [21:23<2:38:34,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.21369    loss g: -1.50627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9903/100001 [21:34<2:38:44,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.94226    loss g: -1.74704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10000/100001 [21:45<2:41:18,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.50970    loss g: -1.54530\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 1.4244364220170063\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063]\n",
      "New min fid score: 1.424436422017\n",
      "Saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 10101/100001 [22:20<2:48:46,  8.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.05532    loss g: -1.08351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10201/100001 [22:31<2:48:05,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.72830    loss g: -1.55999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10303/100001 [22:42<2:38:36,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.94033    loss g: -1.55620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10401/100001 [22:53<2:43:32,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.39994    loss g: -1.55370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10502/100001 [23:03<2:41:54,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.75260    loss g: -1.34532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10601/100001 [23:14<2:44:09,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.14303    loss g: -1.53627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10701/100001 [23:25<2:47:52,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.14861    loss g: -1.51932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10801/100001 [23:36<2:48:46,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.46986    loss g: -1.35426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10901/100001 [23:47<2:43:13,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.68550    loss g: -1.60813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11000/100001 [23:57<2:41:39,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.82173    loss g: -1.30492\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11001/100001 [24:19<161:54:49,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 1.7734012032279587\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063, 1.7734012032279587]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:15<?, ?it/s]42:07,  9.14it/s]  \n",
      "  0%|          | 0/15 [00:05<?, ?it/s]\n",
      " 11%|█         | 11101/100001 [24:30<2:45:18,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.85652    loss g: -1.25321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11203/100001 [24:41<2:38:37,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.26663    loss g: -1.74984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 11301/100001 [24:51<2:42:41,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.76484    loss g: -1.41681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 11401/100001 [25:02<2:45:11,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.91138    loss g: -1.27900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11501/100001 [25:13<2:43:46,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.06161    loss g: -1.61632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11601/100001 [25:24<2:45:04,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.99370    loss g: -1.26525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11701/100001 [25:35<2:45:25,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.46499    loss g: -1.51946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11801/100001 [25:45<2:44:44,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.27958    loss g: -1.42513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11901/100001 [25:56<2:42:14,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.18842    loss g: -1.53997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12000/100001 [26:07<2:40:41,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.15167    loss g: -1.03276\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12001/100001 [26:29<160:50:12,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.6923654152505065\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063, 1.7734012032279587, 2.6923654152505065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:11<?, ?it/s]:55:01,  2.04s/it] \n",
      "  0%|          | 0/15 [00:01<?, ?it/s]\n",
      " 12%|█▏        | 12102/100001 [26:40<2:39:11,  9.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.12807    loss g: -1.00688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12201/100001 [26:50<2:47:43,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.11418    loss g: -1.69643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12301/100001 [27:01<2:44:01,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.00021    loss g: -1.64647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12401/100001 [27:12<2:45:40,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.90045    loss g: -2.00400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12501/100001 [27:23<2:42:55,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.03355    loss g: -1.23775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12601/100001 [27:34<2:45:33,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.58045    loss g: -1.57991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12701/100001 [27:44<2:43:38,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.00845    loss g: -1.36642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12801/100001 [27:55<2:42:06,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 4.22180    loss g: -2.06550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12902/100001 [28:06<2:39:39,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.41810    loss g: -1.67268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13000/100001 [28:17<2:35:52,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.24740    loss g: -1.27310\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13002/100001 [28:38<110:34:25,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.2885171210583\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063, 1.7734012032279587, 2.6923654152505065, 2.2885171210583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]35:26,  9.32it/s]  \n",
      "  0%|          | 0/15 [00:06<?, ?it/s]\n",
      " 13%|█▎        | 13103/100001 [28:49<2:33:48,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.96846    loss g: -2.02545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13201/100001 [29:00<2:42:33,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.89442    loss g: -1.66532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13303/100001 [29:11<2:34:06,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.24373    loss g: -1.38958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13401/100001 [29:21<2:39:59,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.61800    loss g: -1.34025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 13503/100001 [29:32<2:32:03,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.21504    loss g: -1.49369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 13601/100001 [29:43<2:40:25,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.41292    loss g: -1.55825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 13701/100001 [29:54<2:39:15,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.97870    loss g: -2.16082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 13802/100001 [30:05<2:38:28,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.77579    loss g: -1.39255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 13902/100001 [30:16<2:34:23,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.02161    loss g: -1.59949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14000/100001 [30:26<2:32:39,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.67218    loss g: -1.30140\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14001/100001 [30:48<156:56:45,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 2.803971119026391\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063, 1.7734012032279587, 2.6923654152505065, 2.2885171210583, 2.803971119026391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:11<?, ?it/s]:05:21,  2.72s/it] \n",
      "  0%|          | 0/15 [00:01<?, ?it/s]\n",
      " 14%|█▍        | 14101/100001 [30:59<2:39:10,  8.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.51574    loss g: -1.39225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14203/100001 [31:10<2:32:07,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.96347    loss g: -1.59324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14301/100001 [31:20<2:38:06,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.08160    loss g: -2.12001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14403/100001 [31:31<2:31:11,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.75211    loss g: -1.81710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14501/100001 [31:42<2:41:14,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.81091    loss g: -1.54859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14601/100001 [31:52<2:35:58,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 1.96406    loss g: -1.31934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14703/100001 [32:03<2:29:58,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.35916    loss g: -1.77755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14801/100001 [32:14<2:38:32,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 3.36052    loss g: -1.59251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14901/100001 [32:25<2:37:50,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.89539    loss g: -1.36090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 15000/100001 [32:36<2:34:12,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.15841    loss g: -1.64932\n",
      "saving current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synthetic images: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15001/100001 [32:57<154:34:40,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fid score: 3.15776498192818\n",
      "Fid scores: [5.224418162935107, 2.7267402617327505, 2.99193364529928, 2.9600639632925656, 3.2043104988962963, 3.387689638897349, 3.2454028512116437, 3.2242844127001717, 2.2907345560428425, 1.4905136751897707, 1.4244364220170063, 1.7734012032279587, 2.6923654152505065, 2.2885171210583, 2.803971119026391, 3.15776498192818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:16<?, ?it/s]34:17,  9.18it/s]  \n",
      "  0%|          | 0/15 [00:06<?, ?it/s]\n",
      " 15%|█▌        | 15101/100001 [33:08<2:40:25,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.70859    loss g: -1.39655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15201/100001 [33:19<2:39:34,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.19748    loss g: -1.43639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15302/100001 [33:30<2:33:52,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.22585    loss g: -1.73944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15401/100001 [33:40<2:35:19,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.85088    loss g: -1.71936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 15501/100001 [33:51<2:36:33,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.44752    loss g: -1.10908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 15601/100001 [34:02<2:36:03,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN: loss d: 2.63954    loss g: -1.41018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 15609/100001 [34:03<2:28:06,  9.50it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import utils as vutils\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from scipy import linalg\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "from diffaug import DiffAugment\n",
    "\n",
    "policy = 'color,translation'\n",
    "\n",
    "\n",
    "class FIDScore:\n",
    "    def __init__(self, path_a, path_b, image_size, batch_size, device='cuda'):\n",
    "        self.device = device\n",
    "        self.image_size = image_size\n",
    "        self.path_a = path_a\n",
    "        self.path_b = path_b\n",
    "        self.batch_size = batch_size\n",
    "        self.inception = self.load_patched_inception_v3().eval().to(device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, loader):\n",
    "        #for batch_idx, batch_data in enumerate(loader):\n",
    "            #print(f\"Batch {batch_idx} - Batch shape: {batch_data.shape}, Batch contents: {batch_data}\")\n",
    "        pbar = tqdm(loader)\n",
    "        feature_list = []\n",
    "        for img in loader:\n",
    "            img = img.to(self.device)\n",
    "            feature = self.inception(img)[0].view(img.shape[0], -1)\n",
    "            feature_list.append(feature.to('cpu'))\n",
    "        features = torch.cat(feature_list, 0)\n",
    "        return features\n",
    "\n",
    "    def calc_fid(self, sample_mean, sample_cov, real_mean, real_cov, eps=1e-6):\n",
    "        cov_sqrt, _ = linalg.sqrtm(sample_cov @ real_cov, disp=False)\n",
    "        if not np.isfinite(cov_sqrt).all():\n",
    "            print('product of cov matrices is singular')\n",
    "            offset = np.eye(sample_cov.shape[0]) * eps\n",
    "            cov_sqrt = linalg.sqrtm((sample_cov + offset) @ (real_cov + offset))\n",
    "        if np.iscomplexobj(cov_sqrt):\n",
    "            if not np.allclose(np.diagonal(cov_sqrt).imag, 0, atol=1e-3):\n",
    "                m = np.max(np.abs(cov_sqrt.imag))\n",
    "                raise ValueError(f'Imaginary component {m}')\n",
    "            cov_sqrt = cov_sqrt.real\n",
    "        mean_diff = sample_mean - real_mean\n",
    "        mean_norm = mean_diff @ mean_diff\n",
    "        trace = np.trace(sample_cov) + np.trace(real_cov) - 2 * np.trace(cov_sqrt)\n",
    "        fid = mean_norm + trace\n",
    "        return fid\n",
    "\n",
    "    def __call__(self, num_workers=4):\n",
    "        dset_a = ImageFolder(self.path_a, self.transform)\n",
    "        print(\"Number of real images:\", len(dset_a))\n",
    "        loader_a = DataLoader(dset_a, batch_size=self.batch_size, num_workers=num_workers, drop_last=True)\n",
    "        features_a = self.extract_features(loader_a).numpy()\n",
    "        real_mean = np.mean(features_a, 0)\n",
    "        real_cov = np.cov(features_a, rowvar=False)\n",
    "\n",
    "        dset_b = ImageFolder(self.path_b, self.transform)\n",
    "        print(\"Number of synthetic images:\", len(dset_b))\n",
    "        loader_b = DataLoader(dset_b, batch_size=self.batch_size, num_workers=num_workers, drop_last=True)\n",
    "        features_b = self.extract_features(loader_b).numpy()\n",
    "        sample_mean = np.mean(features_b, 0)\n",
    "        sample_cov = np.cov(features_b, rowvar=False)\n",
    "\n",
    "        fid = self.calc_fid(sample_mean, sample_cov, real_mean, real_cov)\n",
    "\n",
    "        return fid\n",
    "\n",
    "    @staticmethod\n",
    "    def load_patched_inception_v3():\n",
    "        inception = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)\n",
    "        inception.fc = nn.Identity()\n",
    "        return inception\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def crop_image_by_part(image, part):\n",
    "    hw = image.shape[2] // 2\n",
    "    if part == 0:\n",
    "        return image[:, :, :hw, :hw]\n",
    "    if part == 1:\n",
    "        return image[:, :, :hw, hw:]\n",
    "    if part == 2:\n",
    "        return image[:, :, hw:, :hw]\n",
    "    if part == 3:\n",
    "        return image[:, :, hw:, hw:]\n",
    "\n",
    "\n",
    "def train_d(net, data, label=\"real\"):\n",
    "    \"\"\"Train function of discriminator\"\"\"\n",
    "    if label == \"real\":\n",
    "        part = random.randint(0, 3)\n",
    "        pred, [rec_all, rec_small, rec_part] = net(data, label, part=part)\n",
    "        err = F.relu(torch.rand_like(pred) * 0.2 + 0.8 - pred).mean()\n",
    "        err.backward()\n",
    "        return pred.mean().item(), rec_all, rec_small, rec_part\n",
    "    else:\n",
    "        pred = net(data, label)\n",
    "        err = F.relu(torch.rand_like(pred) * 0.2 + 0.8 + pred).mean()\n",
    "        err.backward()\n",
    "        return pred.mean().item()\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    data_root = args.path\n",
    "    total_iterations = args.iter\n",
    "    checkpoint = args.ckpt\n",
    "    batch_size = args.batch_size\n",
    "    im_size = args.im_size\n",
    "    ndf = 64\n",
    "    ngf = 64\n",
    "    nz = args.noise_dim\n",
    "    nlr = 0.0001\n",
    "    nbeta1 = 0.5\n",
    "    use_cuda = True\n",
    "    multi_gpu = True\n",
    "    dataloader_workers = 8\n",
    "    current_iteration = args.start_iter\n",
    "    save_interval = 100\n",
    "    saved_model_folder, saved_image_folder = get_dir(args)\n",
    "    fid_batch_size = args.fid_batch_size\n",
    "    save_results_dir = args.name\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "\n",
    "    transform_list = [\n",
    "        transforms.Resize((int(im_size), int(im_size))),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    trans = transforms.Compose(transform_list)\n",
    "\n",
    "    if 'lmdb' in data_root:\n",
    "        from operation import MultiResolutionDataset\n",
    "        dataset = MultiResolutionDataset(data_root, trans, 1024)\n",
    "    else:\n",
    "        dataset = ImageFolder(root=data_root, transform=trans)\n",
    "\n",
    "    dataloader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                                 sampler=InfiniteSamplerWrapper(dataset), num_workers=dataloader_workers,\n",
    "                                 pin_memory=True))\n",
    "    '''\n",
    "    loader = MultiEpochsDataLoader(dataset, batch_size=batch_size, \n",
    "                               shuffle=True, num_workers=dataloader_workers, \n",
    "                               pin_memory=True)\n",
    "    dataloader = CudaDataLoader(loader, 'cuda')\n",
    "    '''\n",
    "\n",
    "    # from model_s import Generator, Discriminator\n",
    "    netG = Generator(ngf=ngf, nz=nz, im_size=im_size)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    netD = Discriminator(ndf=ndf, im_size=im_size)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    netG.to(device)\n",
    "    netD.to(device)\n",
    "\n",
    "    avg_param_G = copy_G_params(netG)\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n",
    "    \n",
    "    generated_images = os.path.join(os.getcwd(), 'train_results', save_results_dir, \"images\")    \n",
    "    fid = FIDScore(data_root, generated_images, im_size, fid_batch_size)\n",
    "    fid_scores = []\n",
    "    min_fid_score = 999\n",
    "\n",
    "    if checkpoint != 'None':\n",
    "        ckpt = torch.load(checkpoint)\n",
    "        netG.load_state_dict({k.replace('module.', ''): v for k, v in ckpt['g'].items()})\n",
    "        netD.load_state_dict({k.replace('module.', ''): v for k, v in ckpt['d'].items()})\n",
    "        avg_param_G = ckpt['g_ema']\n",
    "        optimizerG.load_state_dict(ckpt['opt_g'])\n",
    "        optimizerD.load_state_dict(ckpt['opt_d'])\n",
    "        current_iteration = int(checkpoint.split('_')[-1].split('.')[0])\n",
    "        del ckpt\n",
    "\n",
    "    if multi_gpu:\n",
    "        netG = nn.DataParallel(netG.to(device))\n",
    "        netD = nn.DataParallel(netD.to(device))\n",
    "\n",
    "    for iteration in tqdm(range(current_iteration, total_iterations + 1)):\n",
    "        real_image = next(dataloader)\n",
    "        real_image = real_image.to(device)\n",
    "        current_batch_size = real_image.size(0)\n",
    "        noise = torch.Tensor(current_batch_size, nz).normal_(0, 1).to(device)\n",
    "\n",
    "        fake_images = netG(noise)\n",
    "\n",
    "        real_image = DiffAugment(real_image, policy=policy)\n",
    "        fake_images = [DiffAugment(fake, policy=policy) for fake in fake_images]\n",
    "\n",
    "        ## 2. train Discriminator\n",
    "        netD.zero_grad()\n",
    "\n",
    "        err_dr, rec_img_all, rec_img_small, rec_img_part = train_d(netD, real_image, label=\"real\")\n",
    "        train_d(netD, [fi.detach() for fi in fake_images], label=\"fake\")\n",
    "        optimizerD.step()\n",
    "\n",
    "        ## 3. train Generator\n",
    "        netG.zero_grad()\n",
    "        pred_g = netD(fake_images, \"fake\")\n",
    "        err_g = -pred_g.mean()\n",
    "\n",
    "        err_g.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        for p, avg_p in zip(netG.parameters(), avg_param_G):\n",
    "            avg_p.mul_(0.999).add_(0.001 * p.data)\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(\"GAN: loss d: %.5f    loss g: %.5f\" % (err_dr, -err_g.item()))\n",
    "\n",
    "        \n",
    "        if iteration % (save_interval * 10) == 0 or iteration == total_iterations:\n",
    "            backup_para = copy_G_params(netG)\n",
    "            load_params(netG, avg_param_G)\n",
    "            print (\"saving current model\")\n",
    "            torch.save({'g': netG.state_dict(), 'd': netD.state_dict()}, saved_model_folder + '/last_model.pth')\n",
    "            with torch.no_grad():\n",
    "                for i in range (500):\n",
    "                    fixed_noise = torch.FloatTensor(1, nz).normal_(0, 1).to(device)\n",
    "                    generated_images = netG(fixed_noise)                \n",
    "                    #print(\"saved %d image\" % i)\n",
    "                    vutils.save_image(generated_images[0].add(1).mul(0.5), saved_image_folder + '/%d.jpg' % i)\n",
    "\n",
    "            fid_score = fid()\n",
    "            fid_scores.append(fid_score)\n",
    "            print ('Current fid score:' , fid_score)\n",
    "            print ('Fid scores:' , fid_scores)\n",
    "            \n",
    "            fid_results_path = os.path.join(os.getcwd(), 'train_results', save_results_dir, \"fid.txt\")    \n",
    "\n",
    "            with open(fid_results_path, 'w') as file:\n",
    "                for value in fid_scores:\n",
    "                    file.write(str(value) + '\\n')\n",
    "            \n",
    "            if fid_score < min_fid_score:\n",
    "                min_fid_score = fid_score\n",
    "                print('New min fid score: %.12f' % fid_score)\n",
    "                print('Saving best model')\n",
    "                torch.save({'g': netG.state_dict(), 'd': netD.state_dict()}, saved_model_folder + '/min_fid_model.pth')\n",
    "                #load_params(netG, backup_para)\n",
    "                #torch.save({'g': netG.state_dict(), 'd': netD.state_dict(), 'g_ema': avg_param_G, 'opt_g': optimizerG.state_dict(), 'opt_d': optimizerD.state_dict()}, saved_model_folder + '/all_%d.pth' % iteration)\n",
    "\n",
    "            load_params(netG, backup_para)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #data_root = os.path.join(os.path.abspath('..'), \"datasets\", \"drive\", \"img\")\n",
    "    data_root = os.path.join(os.path.abspath('..'), \"datasets\", \"BV\", \"img\")\n",
    "    print (data_root)\n",
    "    args = easydict.EasyDict({\n",
    "        \"path\": data_root,\n",
    "        \"cuda\": 0,\n",
    "        \"name\": 'test_bv_256',\n",
    "        \"iter\": 100000,\n",
    "        \"start_iter\": 0, \n",
    "        \"batch_size\": 1,\n",
    "        \"im_size\": 256,\n",
    "        \"ckpt\": 'None',\n",
    "        \"noise_dim\": 400,\n",
    "        \"fid_batch_size\": 32\n",
    "    })\n",
    "    \n",
    "    print(args)\n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
