{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "seq = nn.Sequential\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        try:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        except:\n",
    "            pass\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def conv2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.Conv2d(*args, **kwargs))\n",
    "\n",
    "def convTranspose2d(*args, **kwargs):\n",
    "    return spectral_norm(nn.ConvTranspose2d(*args, **kwargs))\n",
    "\n",
    "def batchNorm2d(*args, **kwargs):\n",
    "    return nn.BatchNorm2d(*args, **kwargs)\n",
    "\n",
    "def linear(*args, **kwargs):\n",
    "    return spectral_norm(nn.Linear(*args, **kwargs))\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input * torch.rsqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.target_shape = shape\n",
    "\n",
    "    def forward(self, feat):\n",
    "        batch = feat.shape[0]\n",
    "        return feat.view(batch, *self.target_shape)        \n",
    "\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        nc = x.size(1)\n",
    "        assert nc % 2 == 0, 'channels dont divide 2!'\n",
    "        nc = int(nc/2)\n",
    "        return x[:, :nc] * torch.sigmoid(x[:, nc:])\n",
    "\n",
    "\n",
    "class NoiseInjection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, feat, noise=None):\n",
    "        if noise is None:\n",
    "            batch, _, height, width = feat.shape\n",
    "            noise = torch.randn(batch, 1, height, width).to(feat.device)\n",
    "\n",
    "        return feat + self.weight * noise\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, feat):\n",
    "        return feat * torch.sigmoid(feat)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(4), \n",
    "                                    conv2d(ch_in, ch_out, 4, 1, 0, bias=False), Swish(),\n",
    "                                    conv2d(ch_out, ch_out, 1, 1, 0, bias=False), nn.Sigmoid() )\n",
    "\n",
    "    def forward(self, feat_small, feat_big):\n",
    "        return feat_big * self.main(feat_small)\n",
    "\n",
    "\n",
    "class InitLayer(nn.Module):\n",
    "    def __init__(self, nz, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "                        convTranspose2d(nz, channel*2, 4, 1, 0, bias=False),\n",
    "                        batchNorm2d(channel*2), GLU() )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1, 1, 1)\n",
    "        return self.init(noise)\n",
    "\n",
    "\n",
    "def UpBlock(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        batchNorm2d(out_planes*2), GLU())\n",
    "    return block\n",
    "\n",
    "\n",
    "def UpBlockComp(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        #convTranspose2d(in_planes, out_planes*2, 4, 2, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU(),\n",
    "        conv2d(out_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "        NoiseInjection(),\n",
    "        batchNorm2d(out_planes*2), GLU()\n",
    "        )\n",
    "    return block\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf=64, nz=100, nc=3, im_size=1024):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ngf)\n",
    "\n",
    "        self.im_size = im_size\n",
    "\n",
    "        self.init = InitLayer(nz, channel=nfc[4])\n",
    "                                \n",
    "        self.feat_8   = UpBlockComp(nfc[4], nfc[8])\n",
    "        self.feat_16  = UpBlock(nfc[8], nfc[16])\n",
    "        self.feat_32  = UpBlockComp(nfc[16], nfc[32])\n",
    "        self.feat_64  = UpBlock(nfc[32], nfc[64])\n",
    "        self.feat_128 = UpBlockComp(nfc[64], nfc[128])  \n",
    "        self.feat_256 = UpBlock(nfc[128], nfc[256]) \n",
    "\n",
    "        self.se_64  = SEBlock(nfc[4], nfc[64])\n",
    "        self.se_128 = SEBlock(nfc[8], nfc[128])\n",
    "        self.se_256 = SEBlock(nfc[16], nfc[256])\n",
    "\n",
    "        self.to_128 = conv2d(nfc[128], nc, 1, 1, 0, bias=False) \n",
    "        self.to_big = conv2d(nfc[im_size], nc, 3, 1, 1, bias=False) \n",
    "        \n",
    "        if im_size > 256:\n",
    "            self.feat_512 = UpBlockComp(nfc[256], nfc[512]) \n",
    "            self.se_512 = SEBlock(nfc[32], nfc[512])\n",
    "        if im_size > 512:\n",
    "            self.feat_1024 = UpBlock(nfc[512], nfc[1024])  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        feat_4   = self.init(input)\n",
    "        feat_8   = self.feat_8(feat_4)\n",
    "        feat_16  = self.feat_16(feat_8)\n",
    "        feat_32  = self.feat_32(feat_16)\n",
    "\n",
    "        feat_64  = self.se_64( feat_4, self.feat_64(feat_32) )\n",
    "\n",
    "        feat_128 = self.se_128( feat_8, self.feat_128(feat_64) )\n",
    "\n",
    "        feat_256 = self.se_256( feat_16, self.feat_256(feat_128) )\n",
    "\n",
    "        if self.im_size == 256:\n",
    "            return [self.to_big(feat_256), self.to_128(feat_128)]\n",
    "        \n",
    "        feat_512 = self.se_512( feat_32, self.feat_512(feat_256) )\n",
    "        if self.im_size == 512:\n",
    "            return [self.to_big(feat_512), self.to_128(feat_128)]\n",
    "\n",
    "        feat_1024 = self.feat_1024(feat_512)\n",
    "\n",
    "        im_128 = torch.tanh(self.to_128(feat_128))\n",
    "        im_1024 = torch.tanh(self.to_big(feat_1024))\n",
    "\n",
    "        return [im_1024, im_128]\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlock, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return self.main(feat)\n",
    "\n",
    "\n",
    "class DownBlockComp(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(DownBlockComp, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2, inplace=True),\n",
    "            conv2d(out_planes, out_planes, 3, 1, 1, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        self.direct = nn.Sequential(\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            conv2d(in_planes, out_planes, 1, 1, 0, bias=False),\n",
    "            batchNorm2d(out_planes), nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return (self.main(feat) + self.direct(feat)) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:16, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        if im_size == 1024:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[1024], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    conv2d(nfc[1024], nfc[512], 4, 2, 1, bias=False),\n",
    "                                    batchNorm2d(nfc[512]),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        elif im_size == 512:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 4, 2, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "        elif im_size == 256:\n",
    "            self.down_from_big = nn.Sequential( \n",
    "                                    conv2d(nc, nfc[512], 3, 1, 1, bias=False),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True) )\n",
    "\n",
    "        self.down_4  = DownBlockComp(nfc[512], nfc[256])\n",
    "        self.down_8  = DownBlockComp(nfc[256], nfc[128])\n",
    "        self.down_16 = DownBlockComp(nfc[128], nfc[64])\n",
    "        self.down_32 = DownBlockComp(nfc[64],  nfc[32])\n",
    "        self.down_64 = DownBlockComp(nfc[32],  nfc[16])\n",
    "\n",
    "        self.rf_big = nn.Sequential(\n",
    "                            conv2d(nfc[16] , nfc[8], 1, 1, 0, bias=False),\n",
    "                            batchNorm2d(nfc[8]), nn.LeakyReLU(0.2, inplace=True),\n",
    "                            conv2d(nfc[8], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.se_2_16 = SEBlock(nfc[512], nfc[64])\n",
    "        self.se_4_32 = SEBlock(nfc[256], nfc[32])\n",
    "        self.se_8_64 = SEBlock(nfc[128], nfc[16])\n",
    "        \n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "\n",
    "        self.rf_small = conv2d(nfc[32], 1, 4, 1, 0, bias=False)\n",
    "\n",
    "        self.decoder_big = SimpleDecoder(nfc[16], nc)\n",
    "        self.decoder_part = SimpleDecoder(nfc[32], nc)\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, imgs, label, part=None):\n",
    "        if type(imgs) is not list:\n",
    "            imgs = [F.interpolate(imgs, size=self.im_size), F.interpolate(imgs, size=128)]\n",
    "\n",
    "        feat_2 = self.down_from_big(imgs[0])        \n",
    "        feat_4 = self.down_4(feat_2)\n",
    "        feat_8 = self.down_8(feat_4)\n",
    "        \n",
    "        feat_16 = self.down_16(feat_8)\n",
    "        feat_16 = self.se_2_16(feat_2, feat_16)\n",
    "\n",
    "        feat_32 = self.down_32(feat_16)\n",
    "        feat_32 = self.se_4_32(feat_4, feat_32)\n",
    "        \n",
    "        feat_last = self.down_64(feat_32)\n",
    "        feat_last = self.se_8_64(feat_8, feat_last)\n",
    "\n",
    "        #rf_0 = torch.cat([self.rf_big_1(feat_last).view(-1),self.rf_big_2(feat_last).view(-1)])\n",
    "        #rff_big = torch.sigmoid(self.rf_factor_big)\n",
    "        rf_0 = self.rf_big(feat_last).view(-1)\n",
    "\n",
    "        feat_small = self.down_from_small(imgs[1])\n",
    "        #rf_1 = torch.cat([self.rf_small_1(feat_small).view(-1),self.rf_small_2(feat_small).view(-1)])\n",
    "        rf_1 = self.rf_small(feat_small).view(-1)\n",
    "\n",
    "        if label=='real':    \n",
    "            rec_img_big = self.decoder_big(feat_last)\n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            assert part is not None\n",
    "            rec_img_part = None\n",
    "            if part==0:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,:8])\n",
    "            if part==1:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,:8,8:])\n",
    "            if part==2:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,:8])\n",
    "            if part==3:\n",
    "                rec_img_part = self.decoder_part(feat_32[:,:,8:,8:])\n",
    "\n",
    "            return torch.cat([rf_0, rf_1]) , [rec_img_big, rec_img_small, rec_img_part]\n",
    "\n",
    "        return torch.cat([rf_0, rf_1]) \n",
    "\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    \"\"\"docstring for CAN_SimpleDecoder\"\"\"\n",
    "    def __init__(self, nfc_in=64, nc=3):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:4, 32:2, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*32)\n",
    "\n",
    "        def upBlock(in_planes, out_planes):\n",
    "            block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                conv2d(in_planes, out_planes*2, 3, 1, 1, bias=False),\n",
    "                batchNorm2d(out_planes*2), GLU())\n",
    "            return block\n",
    "\n",
    "        self.main = nn.Sequential(  nn.AdaptiveAvgPool2d(8),\n",
    "                                    upBlock(nfc_in, nfc[16]) ,\n",
    "                                    upBlock(nfc[16], nfc[32]),\n",
    "                                    upBlock(nfc[32], nfc[64]),\n",
    "                                    upBlock(nfc[64], nfc[128]),\n",
    "                                    conv2d(nfc[128], nc, 3, 1, 1, bias=False),\n",
    "                                    nn.Tanh() )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape: c x 4 x 4\n",
    "        return self.main(input)\n",
    "\n",
    "from random import randint\n",
    "def random_crop(image, size):\n",
    "    h, w = image.shape[2:]\n",
    "    ch = randint(0, h-size-1)\n",
    "    cw = randint(0, w-size-1)\n",
    "    return image[:,:,ch:ch+size,cw:cw+size]\n",
    "\n",
    "class TextureDiscriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3, im_size=512):\n",
    "        super(TextureDiscriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.im_size = im_size\n",
    "\n",
    "        nfc_multi = {4:16, 8:8, 16:8, 32:4, 64:2, 128:1, 256:0.5, 512:0.25, 1024:0.125}\n",
    "        nfc = {}\n",
    "        for k, v in nfc_multi.items():\n",
    "            nfc[k] = int(v*ndf)\n",
    "\n",
    "        self.down_from_small = nn.Sequential( \n",
    "                                            conv2d(nc, nfc[256], 4, 2, 1, bias=False), \n",
    "                                            nn.LeakyReLU(0.2, inplace=True),\n",
    "                                            DownBlock(nfc[256],  nfc[128]),\n",
    "                                            DownBlock(nfc[128],  nfc[64]),\n",
    "                                            DownBlock(nfc[64],  nfc[32]), )\n",
    "        self.rf_small = nn.Sequential(\n",
    "                            conv2d(nfc[16], 1, 4, 1, 0, bias=False))\n",
    "\n",
    "        self.decoder_small = SimpleDecoder(nfc[32], nc)\n",
    "        \n",
    "    def forward(self, img, label):\n",
    "        img = random_crop(img, size=128)\n",
    "\n",
    "        feat_small = self.down_from_small(img)\n",
    "        rf = self.rf_small(feat_small).view(-1)\n",
    "        \n",
    "        if label=='real':    \n",
    "            rec_img_small = self.decoder_small(feat_small)\n",
    "\n",
    "            return rf, rec_img_small, img\n",
    "\n",
    "        return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\backup\\Facultad\\Tesis\\NN\\FastGAN\\train_results\\test_bv_256\\models\\min_fid_model_old.pth\n",
      "load checkpoint success\n",
      "load original dataset success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5626/5626 [03:38<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving matrix\n",
      "Matrix saved\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "\n",
    "def load_params(model, new_param):\n",
    "    for p, new_p in zip(model.parameters(), new_param):\n",
    "        p.data.copy_(new_p)\n",
    "\n",
    "def resize(img):\n",
    "    return F.interpolate(img, size=256)\n",
    "\n",
    "def batch_generate(zs, netG, batch=8):\n",
    "    g_images = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(zs)//batch):\n",
    "            g_images.append( netG(zs[i*batch:(i+1)*batch]).cpu() )\n",
    "        if len(zs)%batch>0:\n",
    "            g_images.append( netG(zs[-(len(zs)%batch):]).cpu() )\n",
    "    return torch.cat(g_images)\n",
    "\n",
    "def batch_save(images, folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    for i, image in enumerate(images):\n",
    "        vutils.save_image(image.add(1).mul(0.5), folder_name+'/%d.jpg'%i)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    dataset_size = 5626\n",
    "    total_samples = dataset_size * 1\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "            \"cuda\": 0,\n",
    "            \"name\": 'eval_1',\n",
    "            \"dist\": '.',\n",
    "            \"batch\": 1,\n",
    "            \"im_size\": 256,\n",
    "            \"n_sample\": total_samples,\n",
    "            \"ckpt\": 'None',\n",
    "            \"big\": False,\n",
    "            \"noise_dim\": 400\n",
    "        })\n",
    "    \n",
    "    noise_dim = args.noise_dim\n",
    "    device = torch.device('cuda:%d'%(args.cuda))\n",
    "    \n",
    "    net_ig = Generator(ngf=64, nz=noise_dim, nc=3, im_size=args.im_size)#, big=args.big )\n",
    "    net_ig.to(device)\n",
    "\n",
    "    ckpt = os.path.join(os.getcwd(), 'train_results', 'test_bv_256', 'models', \"min_fid_model_old.pth\")\n",
    "    print (ckpt)\n",
    "    #ckpt = f\"{args.artifacts}/models/{epoch}.pth\"\n",
    "    checkpoint = torch.load(ckpt, map_location=lambda a,b: a)\n",
    "    # Remove prefix `module`.\n",
    "    checkpoint['g'] = {k.replace('module.', ''): v for k, v in checkpoint['g'].items()}\n",
    "    net_ig.load_state_dict(checkpoint['g'])\n",
    "    #load_params(net_ig, checkpoint['g_ema'])\n",
    "\n",
    "    #net_ig.eval()\n",
    "    print('load checkpoint success')\n",
    "\n",
    "    original_dataset = np.load('train_data.npy')\n",
    "    print('load original dataset success')\n",
    "\n",
    "\n",
    "    net_ig.to(device)\n",
    "\n",
    "    del checkpoint\n",
    "\n",
    "    dist = 'eval'\n",
    "    dist = os.path.join(dist, 'img')\n",
    "    os.makedirs(dist, exist_ok=True)\n",
    "\n",
    "    generated_images = np.empty((args.im_size*args.im_size, args.n_sample))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(args.n_sample//args.batch)):\n",
    "            noise = torch.randn(args.batch, noise_dim).to(device)\n",
    "            g_imgs = net_ig(noise)[0]\n",
    "            #g_imgs = F.interpolate(g_imgs, 512)\n",
    "            for j, g_img in enumerate( g_imgs ):\n",
    "                # Flatten the generated image to a 1D vector\n",
    "                g_img_flat = g_img[0].view(-1).cpu().numpy()\n",
    "                # Store the flattened image in the numpy array.\n",
    "                generated_images[:, i*args.batch+j] = g_img_flat\n",
    "                if i % 1000 == 0: \n",
    "                    vutils.save_image(g_img[0].add(1).mul(0.5), os.path.join(dist, '%d.png'%(i*args.batch+j)))#, normalize=True, range=(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "    concatenated_dataset = np.concatenate((original_dataset, generated_images), axis=1)\n",
    "\n",
    "    print('Saving matrix')            \n",
    "    np.save('augmented_dataset.npy', concatenated_dataset)\n",
    "    print('Matrix saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu116\n",
      "11.6\n",
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is NOT available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
